{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Load .nc files\n",
    "ds4 = xr.open_dataset(\"predictions_m4_g4_l32.nc\")\n",
    "ds5 = xr.open_dataset(\"predictions_m5_g4_l32.nc\")\n",
    "ds6 = xr.open_dataset(\"predictions_m6_g4_l32.nc\")\n",
    "\n",
    "ds4, ds5, ds6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nc(ds):\n",
    "  # pick only 1 time entry\n",
    "  ds = ds.isel(time=0)\n",
    "\n",
    "  # pick only level 1000\n",
    "  ds = ds.isel(level=-1)\n",
    "\n",
    "  # drop time and level coords\n",
    "  ds = ds.drop_vars([\"time\", \"level\"])\n",
    "\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds4_proc = process_nc(ds4)\n",
    "ds5_proc = process_nc(ds5)\n",
    "ds6_proc = process_nc(ds6)\n",
    "\n",
    "ds4_proc, ds5_proc, ds6_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data.npz (target) from higher mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_npz(ds):\n",
    "  # Define the target variables\n",
    "  target_vars = [\n",
    "      #'geopotential_at_surface',\n",
    "      #'land_sea_mask',\n",
    "      '2m_temperature',\n",
    "      'mean_sea_level_pressure',\n",
    "      '10m_v_component_of_wind',\n",
    "      '10m_u_component_of_wind',\n",
    "      'total_precipitation_6hr',\n",
    "      #'toa_incident_solar_radiation',\n",
    "      'temperature',\n",
    "      'geopotential',\n",
    "      'u_component_of_wind',\n",
    "      'v_component_of_wind',\n",
    "      'vertical_velocity',\n",
    "      'specific_humidity'\n",
    "  ]\n",
    "\n",
    "  # Get the shape of lat and lon\n",
    "  lat_len = len(ds['lat'])  # e.g., 181\n",
    "  lon_len = len(ds['lon'])  # e.g., 360\n",
    "\n",
    "  # Calculate total number of nodes and targets\n",
    "  n_nodes = lat_len * lon_len  # Total number of nodes (lat * lon)\n",
    "  n_targets = len(target_vars)  # Number of target variables (e.g., 14)\n",
    "\n",
    "  # Prepare an empty list to store each flattened variable's data\n",
    "  flattened_vars = []\n",
    "\n",
    "  # Iterate through each target variable and reshape it\n",
    "  for var in target_vars:\n",
    "      data = ds[var].values  # Extract the variable's data as a numpy array\n",
    "\n",
    "      # Check the shape of the data\n",
    "      data_shape = data.shape\n",
    "      print(f\"Shape of {var}: {data_shape}\")  # For debugging purposes\n",
    "\n",
    "      # Flatten the data based on its dimensionality\n",
    "      if len(data_shape) == 2:  # (lat, lon) format\n",
    "          flattened_data = data.reshape(-1)  # Flatten to 1D array\n",
    "      elif len(data_shape) == 3:  # (batch, lat, lon) format\n",
    "          flattened_data = data.reshape(data_shape[0], -1)  # Flatten lat and lon, keep batch\n",
    "      elif len(data_shape) == 4:  # (batch, level, lat, lon) format\n",
    "          flattened_data = data.reshape(data_shape[0] * data_shape[1], -1)  # Flatten batch and level\n",
    "      else:\n",
    "          raise ValueError(f\"Unexpected shape for variable {var}: {data_shape}\")\n",
    "\n",
    "      # Append the flattened data to the list\n",
    "      flattened_vars.append(flattened_data)\n",
    "\n",
    "  # Stack all flattened variables vertically and transpose to get (n_nodes, n_targets)\n",
    "  target_signal = np.vstack(flattened_vars).T  # Shape: (n_nodes, n_targets)\n",
    "\n",
    "  # Display the shape of the target_signal for verification\n",
    "  print(f\"\\nShape of target_signal: {target_signal.shape}\")  # Expected: (n_nodes, n_targets)\n",
    "\n",
    "  # Save the target_signal to an NPZ file with the key 'target'\n",
    "  np.savez(\"data.npz\", target=target_signal)\n",
    "  # Alternatively, to save space, you can use savez_compressed:\n",
    "  # np.savez_compressed(\"data.npz\", target=target_signal)\n",
    "\n",
    "  print(\"\\nSaved target_signal to data.npz with key 'target'\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate points.npy from lower mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_points_npy(ds):\n",
    "  # Flatten lat and lon dimensions and create the coordinates matrix\n",
    "  lat = ds['lat'].values  # Get the latitude values as a numpy array\n",
    "  lon = ds['lon'].values  # Get the longitude values as a numpy array\n",
    "\n",
    "  # Create a meshgrid of latitudes and longitudes\n",
    "  lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "  # Reshape the grids into 1D arrays\n",
    "  lat_flat = lat_grid.flatten()  # Flatten latitude grid into 1D\n",
    "  lon_flat = lon_grid.flatten()  # Flatten longitude grid into 1D\n",
    "\n",
    "  # Combine the flattened lat and lon into a single array of shape (n_nodes, 2)\n",
    "  points = np.vstack((lat_flat, lon_flat)).T  # Stack lat and lon into (n_nodes, 2)\n",
    "\n",
    "  # points now contains coordinates of shape (n_nodes, 2)\n",
    "  print(f\"Shape of points: {points.shape}\")  # Should print (n_nodes, 2)\n",
    "\n",
    "  np.save(\"points.npy\", points)\n",
    "  print(\"\\nSaved points to points.npy\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fourier.npy from lower mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fourier_npy(ds):\n",
    "  # Define the target variables\n",
    "  target_vars = [\n",
    "      #'geopotential_at_surface',\n",
    "      #'land_sea_mask',\n",
    "      '2m_temperature',\n",
    "      'mean_sea_level_pressure',\n",
    "      '10m_v_component_of_wind',\n",
    "      '10m_u_component_of_wind',\n",
    "      'total_precipitation_6hr',\n",
    "      #'toa_incident_solar_radiation',\n",
    "      'temperature',\n",
    "      'geopotential',\n",
    "      'u_component_of_wind',\n",
    "      'v_component_of_wind',\n",
    "      'vertical_velocity',\n",
    "      'specific_humidity'\n",
    "  ]\n",
    "\n",
    "  # Fourier transform results will be stored in this list\n",
    "  fourier_embeddings = []\n",
    "\n",
    "  # Iterate through each target variable\n",
    "  for var in target_vars:\n",
    "      data = ds[var].values  # Get the variable's data as a numpy array\n",
    "      data_shape = data.shape\n",
    "      print(f\"Shape of {var}: {data_shape}\")  # To check if the shape is as expected\n",
    "\n",
    "      if len(data_shape) == 2:  # (lat, lon) format\n",
    "          # Flatten the lat and lon dimensions into a 1D array\n",
    "          flattened_data = data.flatten()  # (n_nodes,)\n",
    "          flattened_data = flattened_data.reshape(-1, 1)  # (n_nodes, 1) to ensure it's a 2D column vector\n",
    "      elif len(data_shape) == 3 and data_shape[0] == 1:  # (1, lat, lon) format\n",
    "          # Remove the batch dimension (squeeze) and flatten lat and lon\n",
    "          data = np.squeeze(data)  # (lat, lon)\n",
    "          flattened_data = data.flatten()  # (n_nodes,)\n",
    "          flattened_data = flattened_data.reshape(-1, 1)  # (n_nodes, 1)\n",
    "      elif len(data_shape) == 3:  # (batch, lat, lon) format\n",
    "          # Flatten lat and lon dimensions, leaving the batch dimension intact\n",
    "          flattened_data = data.reshape(data_shape[0], -1)  # (batch, n_nodes)\n",
    "      else:\n",
    "          raise ValueError(f\"Unexpected shape for variable {var}: {data_shape}\")\n",
    "\n",
    "      # Apply Fourier Transform to each variable (FFT over spatial dimensions)\n",
    "      fourier_transformed = np.fft.fft(flattened_data, axis=1)  # FFT along the spatial (lat, lon) dimension\n",
    "\n",
    "      # Compute magnitude of the Fourier components (or keep real/imaginary parts)\n",
    "      magnitude = np.abs(fourier_transformed)  # Magnitude of the FFT result\n",
    "\n",
    "      # You can choose the number of frequency components (n_fourier)\n",
    "      n_fourier = magnitude.shape[1]  # Number of Fourier coefficients (e.g., for FFT along the lat-lon axis)\n",
    "      print(f\"Number of Fourier components: {n_fourier}\")\n",
    "\n",
    "      # Append the magnitude as a feature in the spectral embeddings\n",
    "      fourier_embeddings.append(magnitude)\n",
    "\n",
    "  # Stack all the Fourier embeddings into a single array\n",
    "  # Ensure that all arrays are reshaped to have the same number of nodes (n_nodes)\n",
    "  fourier_embeddings = np.hstack(fourier_embeddings)  # (n_nodes, n_fourier)\n",
    "\n",
    "  # Now fourier_embeddings contains the spectral embeddings (n_nodes, n_fourier)\n",
    "  print(f\"\\nShape of Fourier embeddings: {fourier_embeddings.shape}\")\n",
    "\n",
    "  np.save(\"fourier.npy\", fourier_embeddings)\n",
    "  print(\"\\nSaved spectral embeddings to fourier.npy\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_M4 = True\n",
    "_M5 = False\n",
    "_M6 = False\n",
    "if _M4:\n",
    "  gen_data_npz(ds4_proc)\n",
    "  gen_points_npy(ds4_proc)\n",
    "  gen_fourier_npy(ds4_proc)\n",
    "elif _M5:\n",
    "  gen_data_npz(ds5_proc)\n",
    "  gen_points_npy(ds5_proc)\n",
    "  gen_fourier_npy(ds5_proc)\n",
    "elif _M6:\n",
    "  gen_data_npz(ds6_proc)\n",
    "  gen_points_npy(ds6_proc)\n",
    "  gen_fourier_npy(ds6_proc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "499",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
